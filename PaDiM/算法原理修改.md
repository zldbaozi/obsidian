## 1、在修改的时候，出现了训练和推理的tensor不匹配的问题

PaDiM算法的核心是将三层特征拼接在一起，为了能拼接，这三个不同尺寸的特征图必须变成相同的尺寸——上采样或者下采样

1. **Layer 1 (Stride 4):** 112/4=28×28
    
2. **Layer 2 (Stride 8):** 112/8=14×14
    
3. **Layer 3 (Stride 16):** 112/16=7×7
    
![[Pasted image 20251230111829.png|1125]]

上采样保证高精度，下采样保证高速度，这里选择的是上采样。
```c++
def _extract_multiscale_features(self, x):
    features = self.feature_extractor(x)
    
    import torch.nn.functional as F
    # 假设 layer1 是最大的 (28x28)
    
    target_size = features[0].shape[-2:]  
    # 表示第一层特征图的高度和宽度，shape[-2:]是python的切片操作，表示从倒数第2个维度开始，取到最后一个维度[B,C,H,W]
    
    resized = [F.interpolate(f, size=target_size, mode='bilinear', align_corners=False) for f in features]
    # 将不同层的特征图调整到相同的尺寸，以便后续拼接。f表示列表中的每一层特征图，F.interpolate()将特征图调整到target_size,bilinear表示双线性插值,align_corners表示避免插值时的边缘对齐问题
    
    out = torch.cat(resized, dim=1)
    # 将所有特征图在通道维度为1上拼接
    
    return out.permute(0, 2, 3, 1) # [B, H, W, C]
```

# 2、python转c++优化推理时间
## 1.随机降维投影优化
原来是scikit-learn（cpu）版本的，速度慢，改为pytorch随机索引切片（矩阵乘法直接随机选100个通道，其余直接舍弃，减少计算）
```c++
# 第二步：随机投影降维（cpu版）

        if reduce_dims and reduce_dims < all_features.shape[-1]:

            print(f"使用随机投影降维: {all_features.shape[-1]} -> {reduce_dims}")

            self.projector = SparseRandomProjection(n_components=reduce_dims)

            # 重塑特征以便投影

            original_shape = all_features.shape

            print("重塑特征矩阵以进行随机投影...")

            all_features_flat = all_features.reshape(-1, original_shape[-1])

            # 执行随机投影并显示进度

            print("正在进行随机投影...")

            all_features_projected = self.projector.fit_transform(all_features_flat)

            print("✅ 随机投影完成!")
```

```c++
# 随机降维(优化后)
        if reduce_dims < C:
            self.selected_indices = torch.randperm(C)[:reduce_dims].to(self.device)
            
            embedding_vectors = torch.index_select(torch.from_numpy(embedding_vectors).to(self.device), 3 ,self.selected_indices).cpu().numpy()
            # torch.from_numpy(embedding_vectors)将原始特征向量(embedding_vectors,numpy)转换为pytorch张量
            # .to(self.device)将张量移动到指定设备
            # torch.index_select()选择特定维度上的子集
            C = reduce_dims
```

## 2.马氏距离计算优化
```c++
# 为每个位置计算马氏距离 ---逐像素循环
        for i in range(H):
            for j in range(W):
                # 获取测试特征
                test_features = features_np[:, i, j, :]  # [B, C]
                
                mean = self.means[i, j]  # [C]
                
                inv_cov = self.inv_covs[i, j]  # [C, C]
                
                diff = test_features - mean  # [B, C]
               
                temp = np.dot(diff, inv_cov)  # [B, C]

                mahalanobis_dist = np.sum(temp * diff, axis=1)  # [B]
                mahalanobis_dist = np.sqrt(np.abs(mahalanobis_dist))

                anomaly_maps[:, i, j] = mahalanobis_dist
```
之前的逐像素计算使用numpy，所有操作都在CPU上完成(无法使用GPU加速，数据需要频繁再numpy和pytorch张量之间转换增加开销)
```c++
# 广播机制计算 (x - μ)
diff = features - self.means.unsqueeze(0)  # [B, H, W, C]

# 使用 einsum 进行批量矩阵乘法
# torch.einsum是pytorch中的爱因斯坦求和约定函数，用于高效地执行张量操作，它的作用是根据指定的索引规则，对输入张量进行维度缩并或变换。
# b: batch, h: height, w: width, i: c_in, j: c_out
#diff的最后一个维度i和inv_covs的倒数第二个维度i是公共维度，这两个维度的元素会逐一相乘并求和，得到结果张量的维度bhwj
#为什么公共维度是i,而不是h,w。因为矩阵乘法的公共维度必须是特征维度，而不是空间维度h,w
temp = torch.einsum('bhwi,hwij->bhwj', diff, self.inv_covs)  # [B, H, W, C]

# 计算马氏距离
mahalanobis_dist = torch.einsum('bhwj,bhwj->bhw', temp, diff)  # [B, H, W]
mahalanobis_dist = torch.sqrt(torch.abs(mahalanobis_dist))
```
现在使用torch的广播机制和einsum一次性对整个特征图的所有像素位置进行计算，所有操作都在GPU上完成(数据始终保持在GPU上，无需频繁转换；einsum是高效的张量操作，能够充分利用GPU的并行计算能力)


==*公共维度的理解*==
*diff:[B,H,W,C],b表示批量大小，h表示特征图的高度，w表示特征图的宽度，i表示输入通道*
*inv_covs:[H,W,C,C],h表示特征图的高度，w表示特征图的宽度，i表示输入通道，j表示输出通道*

假设：
- `B = 2（批量大小为 2）
- `H = 3,W = 3（特征图大小为 3x3）
- `C = 4（特征通道数为 4）。
那么：
- [diff] 的形状是 `[2, 3, 3, 4]`，即每个像素位置 `(h, w)` 有一个长度为 4 的特征向量，也就是1x4的向量。
- [inv_covs] 的形状是 `[3, 3, 4, 4]`，即每个像素位置 `(h, w)` 有一个 4x4 的协方差逆矩阵。
所以公共维度就是`i = 4
``
``mahalanobis_dist = torch.einsum('bhwj,bhwj->bhw', temp, diff)  # [B, H, W]
这行代码的公共维度是j,也就是两个1x4的特征向量相乘，不满足矩阵乘法的要求（第一个矩阵的列数等于第二个矩阵的行数）

为了解决这种问题，可以使矩阵转置后相乘——————涉及到内积还是外积的问题（内积可转置，外积不可以）
==*内积（点积）：表示两个向量的对应元素逐一相乘并求和，结果是一个标量==*
==*外积：表示两个向量的所有元素两两相乘，结果是一个矩阵*==


# 3、在半导体领域无法准确划分OK和NG（元器件本身差异较大）
这是一个非常深刻且切中痛点的问题。在工业半导体检测中，**类内差异大（High Intra-class Variance）** 确实是 PaDiM（及其基于高斯分布建模的方法）的一大软肋。

PaDiM 的核心假设是：每一个空间位置 $(i,j)(i,j)$的特征都服从一个单峰的多元高斯分布 $N(μij,Σij)$
问题的根源在于:当 OK 件之间差异较大（例如：晶圆表面的不同纹理、由于轻微偏移导致的边缘位置变化、不同的批次色差）时，为了包容这些差异，PaDiM 学习到的协方差矩阵 $ΣijΣij​$ 会变得“很大”（方差大）。这会导致分布变得很扁平，那些原本应该被判定为 NG 的缺陷（特别是处于边缘分布的微小缺陷），其马氏距离计算出来不够大，从而混入 OK 分布中，这就是你遇到的 **“NG 误报为 OK”**。

仅仅依靠“最大马氏距离（Max Mahalanobis Distance）”作为整张图的得分，确实不仅不稳定，而且容易受噪声干扰。

要从底层原理出发，构建一个更“综合”的异常得分机制，可以从以下三个维度进行改造：


## 1.引入空间连通性约束（Spatial Consistency）

半导体元器件的缺陷（划痕、崩缺、异物）通常是**连续**的，而不是离散的噪点。PaDiM 原始算法是逐像素（Patch）独立计算距离，忽略了邻域关系。

**改进方案：基于连通域的得分计算,在计算出原始的马氏距离图后，不要直接取值，而是：

1. **高斯平滑（Gaussian Smoothing）：** 先对 Distance Map 进行高斯滤波，抑制孤立的高频噪声。
    
2. **连通域分析（Connected Components）：** 设定一个低阈值进行二值化，提取连通域。
    
3. **综合得分公式：** 定义异常得分为 **“最大连通域的面积** X 该区域的平均马氏距离”**，或者“最大连通域内的马氏距离总和（Mass）”。
                        $Score=max⁡_{blobs}(Area_{blob}×MeanDistance_{blob})$

    原理： 这样，即使某个 OK 件因为纹理差异导致局部有几个点马氏距离很高，但因为形不成连通域，得分会被拉低；而 NG 件即使单点距离不是极高，但因为面积大，总分会很高。
    
行不通，误报的OK图是一大片亮区，NG图是一个小亮斑这是其中一个原因。最主要的原因是PaDiM计算出的原始距离就不对（OK分数>NG分数）


### 2. 底层建模改进：从单高斯到高斯混合模型（GMM）

这是解决“OK件差异大”最本质的方法。  
既然 OK 件在位置 `(i,j)(i,j)`可能呈现多种状态（例如：有时候是引脚的亮光，有时候是引脚的阴影，这都是 OK），那么单峰高斯分布必然拟合得很差。

**改进方案：Patch-wise GMM (Gaussian Mixture Model)**  
在训练阶段，对于每个位置 `(i,j)(i,j)`，不再拟合一个 `N(μ,Σ)N(μ,Σ)`，而是拟合K个高斯分布的混合：  

							$P(x_{ij})=\sum1^Kπ_kN(x_{ij}∣μ_k,Σ_k)$

在推理阶段，计算测试特征到这K个中心中**最近的一个**的马氏距离（或者加权似然度）。

- **实现代价：** 计算量会增加，但在半导体这种高精度场景是值得的。你可以设定 K=3或5，用以覆盖 OK 件的多种模态。

- 替代方案（更轻量）： 如果不想上全量 GMM，可以使用 **K-Means 聚类**。在每个 Patch 位置存K个聚类中心。推理时计算到最近中心的距离。这能有效解决“多模态 OK”导致分布过宽的问题。



### 3. 特征层面的加权（Channel Re-weighting）

PaDiM 提取的特征向量通常有几百维（取决于 Backbone）。对于半导体元器件，有些特征通道（Channel）可能对“纹理变化”很敏感（导致 OK 件之间距离大），而有些通道对“结构缺陷”敏感。原始 PaDiM 对所有通道一视同仁。

**改进方案：基于方差的特征选择/加权**  
在训练阶段，观察每个通道在 OK 数据集上的方差。

- 如果某个通道在 OK 件上的方差极大，说明这个特征不稳定（可能是光照敏感或对齐误差敏感），在计算马氏距离时，应该**降低该维度的权重**。
    
- PaDiM 的 PCA 降维步骤中，可以特意保留那些“在 OK 件内部方差小，但在潜在异常方向上方差大”的分量（虽然无监督很难知道异常方向，但至少可以惩罚高方差特征）。
    

能不能实现半监督学习？？人来不断地告诉它热力图高亮的地方是对是错，进而自己加权。

## 4.修改正则化系数或者resnet18的layer1来增强鲁棒性

	理解正则化系数：正则化系数ϵ相当于是一副“滤音耳塞”，防止过敏反应（一些很微小的瑕疵也报故障）。
	加上ϵ后：给算法设了一个"最低容忍度"，正则化系数的数学操作是：在分母（方差）上强行加一个数值。
                                异常得分≈差异​/方差+ϵ
    这时候，ϵ就扮演了“缓冲垫”的角色。（一般选择0.01-0.1）



	丢弃resnet18的layer1特征，因为layer1提取的是极底层的特征（边缘、纹理细节）。它分辨率高，对微小的对齐误差和高频噪声（如金属表面的颗粒感）极其敏感。
	去掉之后，只用layer2和layer3，相当于让模型“眯着眼睛”看图，忽略细微的噪点，只关注结构性的缺陷。


### 总结实施建议

如果你想快速验证效果，建议按以下顺序尝试，成本由低到高：

1. **修改 Score 计算（即刻见效）：**  
    放弃 max()。实现 **Top-K Pooling**（例如取前 100 个最强像素的均值）。同时，在计算 Score 前，对 Anomaly Map 进行一次 5×5 或 7×7的**高斯模糊**。这能大幅过滤掉由于元器件差异引起的“单点高分误报”。
    
2. **修改推理逻辑（解决微弱 NG）：**  
    使用 **Multi-scale Fusion Score**。不要只看深层特征（语义强但位置模糊），也不要只看浅层特征（纹理强但噪点多）。明确地加权融合不同 Layer 的 Anomaly Map，而不是像原始 PaDiM 那样拼接向量。
    
3. **修改底层模型（根治多模态问题）：**  
    如果上述都没用，说明你的 OK 件差异确实大到了单高斯无法覆盖。此时应放弃标准的 PaDiM，转而使用 **PatchCore** 思想（基于 Memory Bank 的最近邻搜索）或实现 **Patch-wise GMM**。
    
	- 注： **PatchCore** 在处理“OK件差异大”的问题上通常优于 PaDiM，因为它存的是“核心样本库”而不是“平均分布”，只要测试样本离库里任何一个样本近，就算 OK，非常适合多模态分布。


如果在测试这种大一点的晶圆器件时，分辨率也要随之提升，否则会出现无法判断元件NG/OK的情况，因为半导体的芯片分辨率普遍要比之前的高，






